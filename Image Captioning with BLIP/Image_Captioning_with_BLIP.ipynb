{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "QWWnzewoVm3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import gradio as gr\n",
        "\n",
        "# Cek perangkat (GPU jika tersedia)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load processor dan model BLIP\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "\n",
        "# Ukuran standar untuk gambar input\n",
        "STANDARD_SIZE = (384, 384)  # width, height\n",
        "\n",
        "# Fungsi untuk membuat caption\n",
        "def generate_captions(image):\n",
        "    # Resize gambar ke ukuran standar dan ubah ke RGB\n",
        "    image = image.resize(STANDARD_SIZE).convert(\"RGB\")\n",
        "\n",
        "    # Conditional captioning\n",
        "    text = \"a photography of\"\n",
        "    inputs = processor(image, text, return_tensors=\"pt\").to(device)\n",
        "    out_cond = model.generate(**inputs)\n",
        "    caption_conditional = processor.decode(out_cond[0], skip_special_tokens=True)\n",
        "\n",
        "    # Unconditional captioning\n",
        "    inputs = processor(image, return_tensors=\"pt\").to(device)\n",
        "    out_uncond = model.generate(**inputs)\n",
        "    caption_unconditional = processor.decode(out_uncond[0], skip_special_tokens=True)\n",
        "\n",
        "    return caption_conditional, caption_unconditional\n",
        "\n",
        "# UI dengan Gradio\n",
        "interface = gr.Interface(\n",
        "    fn=generate_captions,\n",
        "    inputs=gr.Image(\n",
        "        type=\"pil\",\n",
        "        label=\"Upload Image\",\n",
        "        image_mode=\"RGB\",\n",
        "        width=STANDARD_SIZE[0],\n",
        "        height=STANDARD_SIZE[1]\n",
        "    ),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Conditional Caption (with prompt: 'a photography of')\"),\n",
        "        gr.Textbox(label=\"Unconditional Caption\"),\n",
        "    ],\n",
        "    title=\"Image Captioning with BLIP\",\n",
        "    description=\"Upload an image to get both conditional and unconditional captions using the BLIP model. All images will be resized to 384x384 pixels.\"\n",
        ")\n",
        "\n",
        "# Jalankan Gradio UI\n",
        "if __name__ == \"__main__\":\n",
        "    interface.launch()\n"
      ],
      "metadata": {
        "id": "tsiZ9tUHVlp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}